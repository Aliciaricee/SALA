{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_actiwatch_data.py\n",
    "%run firsttime.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyarrow\n",
    "\n",
    "from joblib import *\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# this is used to make Federal Holidays a nonschool day.  Note that we don't have any\n",
    "# way to recognize school district unique holidays, like teacher work days or such \n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values in this cell to process the data desired\n",
    "\n",
    "global ddirs\n",
    "\n",
    "# dictionary links a unique experimental group with the directory that holds those files\n",
    "# inside that directory are unique files per subject in the group\n",
    "ddirs = {\n",
    "        'Fall 220 2015': '../Fall 220 2015/',\n",
    "        'Fall 220 2016': '../Fall 220 2016/',\n",
    "        'Spring 418 2016': '../Spring 418 2016/',\n",
    "        'Spring 418 2017': '../Spring 418 2017/',\n",
    "        'Spring 418 2018': '../Spring 418 2018/',\n",
    "        'Summer 220 2016': '../Summer 220 2016/',\n",
    "        'Summer 220 2017': '../Summer 220 2017/',\n",
    "        'Winter 220 2018': '../Winter 220 2018/',\n",
    "}\n",
    "\n",
    "# where the saved processed data goes\n",
    "outfile = '../processed data/SeaUgrad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating light timing data ...\n",
      "Adding holiday markers to timing data ...\n"
     ]
    }
   ],
   "source": [
    "recalculate_raw = False # true forces long recalculations, false loads processed data from disk\n",
    "recalculate_timing = False\n",
    "\n",
    "threshs = [ [5], [10], [50], [100], [500], [1000] ] \n",
    "\n",
    "def get_raw_data(season):\n",
    "    rawd, summaryd = load_actiwatch_data(ddirs[season],uidprefix=season)\n",
    "    rawd['Group']=season\n",
    "    return rawd    \n",
    "\n",
    "if recalculate_raw:\n",
    "    print(\"Loading raw from disk ...\")    \n",
    "    results = Parallel(n_jobs=len(ddirs))(delayed(get_raw_data)(season) for season in ddirs.keys())\n",
    "    allData = pd.concat(results)\n",
    "    # the following assignments depend on the datafile names and directory structure being exactly of the form:\n",
    "    # ../Quarter Class 4digitYear/uniqueSubjectID_blahblahwhatever.csv\n",
    "    allData['Quarter']=allData.UID.apply(lambda x: x.split()[0])\n",
    "    allData['Class']=allData.UID.apply(lambda x: x.split()[1])\n",
    "    allData['Year']=allData.UID.apply(lambda x: x.split()[2][:4])\n",
    "    allData['Subject ID']=allData.UID.apply(lambda x: x.split()[2][4:])\n",
    "    allData.to_parquet(outfile+'raw.parquet',engine='fastparquet',compression='gzip')\n",
    "else:\n",
    "    allData = pd.read_parquet(outfile+'raw.parquet')\n",
    "    \n",
    "if recalculate_timing:    \n",
    "    print(\"Calculating light timing data ...\")\n",
    "    \n",
    "    # don't recalculate results if it already exists, takes a long time and a lot of memory\n",
    "    # this has been added as I troubleshoot later manipulations in this cell... should be ok\n",
    "    # if we are recalculating from scratch but this might bite you in the butt if there's some\n",
    "    # weird non-linear cell execution going on with another variable named results\n",
    "    try: results\n",
    "    except NameError:\n",
    "        results = Parallel(n_jobs=len(threshs))(delayed(firstAndLastLight)(allData, threshold) for threshold in threshs)\n",
    "        \n",
    "    timingData = pd.concat(results)\n",
    "    \n",
    "    print(\"Adding holiday markers to timing data ...\")\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=timingData.Date.min(), end=timingData.Date.max())\n",
    "\n",
    "    nn = pd.DatetimeIndex( timingData.Date )\n",
    "    timingData['DayofWeek'] = nn.dayofweek \n",
    "    days = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "    daytype = ['Weekday','Weekday','Weekday','Weekday','Weekday','Weekend/Holiday','Weekend/Holiday']\n",
    "\n",
    "    daygrp=[]\n",
    "    dtpgrp=[]\n",
    "    wkendholiday=[]\n",
    "    for k, row in timingData.iterrows():\n",
    "        daygrp.append(row['Group'].split('seattle')[0] + days[row['DayofWeek']])\n",
    "        if holidays.isin([row['Date']]).any():\n",
    "            dtpgrp.append(row['Group'].split('seattle')[0] + 'Weekend/Holiday')\n",
    "            wkendholiday.append(True)\n",
    "        else:\n",
    "            dtpgrp.append(row['Group'].split('seattle')[0] + daytype[row['DayofWeek']])\n",
    "            if row['DayofWeek'] > 4:\n",
    "                wkendholiday.append(True)\n",
    "            else:\n",
    "                wkendholiday.append(False)\n",
    "\n",
    "    timingData['GroupDayofWeek'] = daygrp\n",
    "    timingData['GroupDayType'] = dtpgrp\n",
    "    timingData['Weekend/Holiday'] = wkendholiday\n",
    "\n",
    "    # missing stuff was here\n",
    "    \n",
    "    timingData['Quarter']=timingData.UID.apply(lambda x: x.split()[0])\n",
    "    timingData['Class']=timingData.UID.apply(lambda x: x.split()[1])\n",
    "    timingData['Year']=timingData.UID.apply(lambda x: x.split()[2][:4])\n",
    "    timingData['Subject ID']=timingData.UID.apply(lambda x: x.split()[2][4:])\n",
    "\n",
    "    #timingData.to_parquet(outfile+'timing.parquet')\n",
    "    # at this moment there are two choices for parquet writing, pyarrow (which does not support Timedelta)\n",
    "    # and fastparquet (which does not support datetime.date )... I'm going to go with the latter\n",
    "    tdc = timingData.copy()\n",
    "    tdc.Date = tdc.Date.astype('datetime64')\n",
    "    tdc['Watch period'] = pd.to_timedelta(tdc['Watch period']) #oops that was a datetime.timedelta, which we dont need that also choked parquet\n",
    "    tdc.to_parquet(outfile+'timing.parquet', engine='fastparquet', compression='gzip')\n",
    "    del(tdc)\n",
    "else:\n",
    "    tdc = pd.read_parquet(outfile+'timing.parquet', engine='fastparquet')\n",
    "    tdc.Date = tdc.Date.apply(lambda x: x.date()) # go back to original data format\n",
    "    timingData = tdc.copy()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter       object\n",
      "Year           int64\n",
      "Class          int64\n",
      "Subject ID     int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subject ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year  Class  Subject ID\n",
       "0      Fall  2015    220           1\n",
       "1      Fall  2015    220           2\n",
       "2      Fall  2015    220           3\n",
       "3      Fall  2015    220           5\n",
       "4      Fall  2015    220           6\n",
       "..      ...   ...    ...         ...\n",
       "438  Winter  2018    220         116\n",
       "439  Winter  2018    220         117\n",
       "440  Winter  2018    220         118\n",
       "441  Winter  2018    220         119\n",
       "442  Winter  2018    220         121\n",
       "\n",
       "[507 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "touse = pd.read_excel('../Subjects Included in Study.xlsx')\n",
    "checkme = touse[['Quarter','Year','Class','Subject ID']].drop_duplicates().sort_values(by=['Quarter', 'Year','Class','Subject ID'])\n",
    "print(checkme.dtypes)\n",
    "checkme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter       object\n",
      "Year           int64\n",
      "Class          int64\n",
      "Subject ID     int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subject ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year  Class  Subject ID\n",
       "0      Fall  2015    220           1\n",
       "1      Fall  2015    220           2\n",
       "2      Fall  2015    220           3\n",
       "3      Fall  2015    220           5\n",
       "4      Fall  2015    220           6\n",
       "..      ...   ...    ...         ...\n",
       "504  Winter  2018    220         116\n",
       "505  Winter  2018    220         117\n",
       "506  Winter  2018    220         118\n",
       "507  Winter  2018    220         119\n",
       "508  Winter  2018    220         121\n",
       "\n",
       "[509 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataids = timingData[['Quarter','Year','Class','Subject ID']].drop_duplicates()\n",
    "dataids['Subject ID'] = dataids['Subject ID'].astype(int)\n",
    "dataids['Year'] = dataids['Year'].astype(int)\n",
    "dataids['Class'] = dataids['Class'].astype(int)\n",
    "dataids.sort_values(by=['Quarter', 'Year','Class','Subject ID'],inplace=True)\n",
    "dataids.reset_index(drop=True,inplace=True)\n",
    "print(dataids.dtypes)\n",
    "dataids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfleischer/opt/anaconda3/envs/light_analysis_2020/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>UID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>57</td>\n",
       "      <td>Winter 220 20180057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>115</td>\n",
       "      <td>Winter 220 20180115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year  Class  Subject ID                  UID\n",
       "463  Winter  2018    220          57  Winter 220 20180057\n",
       "503  Winter  2018    220         115  Winter 220 20180115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat( [dataids, checkme])\n",
    "rmall = df_all.drop_duplicates(keep=False, inplace=False)\n",
    "rmall['UID']=rmall.apply(axis=1, func=lambda x: '{} {} {}{:04d}'.format(x['Quarter'],x['Class'],x['Year'],x['Subject ID']))\n",
    "rmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>UID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>79</td>\n",
       "      <td>Fall 220 20150079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2015</td>\n",
       "      <td>220</td>\n",
       "      <td>114</td>\n",
       "      <td>Fall 220 20150114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>49</td>\n",
       "      <td>Summer 220 20160049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>65</td>\n",
       "      <td>Summer 220 20160065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>Summer 220 20160080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall 220 20160001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>17</td>\n",
       "      <td>Fall 220 20160017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>30</td>\n",
       "      <td>Fall 220 20160030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017</td>\n",
       "      <td>418</td>\n",
       "      <td>62</td>\n",
       "      <td>Spring 418 20170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>55</td>\n",
       "      <td>Winter 220 20180055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>64</td>\n",
       "      <td>Winter 220 20180064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>118</td>\n",
       "      <td>Winter 220 20180118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "      <td>220</td>\n",
       "      <td>121</td>\n",
       "      <td>Winter 220 20180121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2018</td>\n",
       "      <td>418</td>\n",
       "      <td>66</td>\n",
       "      <td>Spring 418 20180066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year  Class  Subject ID                  UID\n",
       "67     Fall  2015    220          79    Fall 220 20150079\n",
       "93     Fall  2015    220         114    Fall 220 20150114\n",
       "200  Summer  2016    220          49  Summer 220 20160049\n",
       "216  Summer  2016    220          65  Summer 220 20160065\n",
       "229  Summer  2016    220          80  Summer 220 20160080\n",
       "232    Fall  2016    220           1    Fall 220 20160001\n",
       "244    Fall  2016    220          17    Fall 220 20160017\n",
       "255    Fall  2016    220          30    Fall 220 20160030\n",
       "323  Spring  2017    418          62  Spring 418 20170062\n",
       "397  Winter  2018    220          55  Winter 220 20180055\n",
       "405  Winter  2018    220          64  Winter 220 20180064\n",
       "440  Winter  2018    220         118  Winter 220 20180118\n",
       "442  Winter  2018    220         121  Winter 220 20180121\n",
       "501  Spring  2018    418          66  Spring 418 20180066"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmweekends = touse.loc[ touse.Notes.dropna().index, ['Quarter','Year','Class','Subject ID'] ]\n",
    "rmweekends['UID']=rmweekends.apply(axis=1, func=lambda x: '{} {} {}{:04d}'.format(x['Quarter'],x['Class'],x['Year'],x['Subject ID']))\n",
    "rmweekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43664740, 15) (47844, 23)\n",
      "(43544129, 15) (47712, 23)\n"
     ]
    }
   ],
   "source": [
    "#remove subjects who don't belong\n",
    "thedata = allData.copy()\n",
    "thetiming = timingData.copy()\n",
    "print(thedata.shape, thetiming.shape)\n",
    "for anid in rmall.UID:\n",
    "    thedata = thedata.query('~(UID == @anid)')\n",
    "    thetiming = thetiming.query('~(UID == @anid)')\n",
    "print(thedata.shape,  thetiming.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     43544129\n",
       "unique           2\n",
       "top          False\n",
       "freq      31506511\n",
       "Name: is_weekend, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thedata['is_weekend'] = thedata.index.dayofweek.isin([5,6])\n",
    "thedata['is_weekend'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241379310344828 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# ratio of weekday to total datapoints is close ot the expected values\n",
    "print(31.5/43.5, 5./7.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetiming['OutofSchool'] = thetiming['Weekend/Holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43544129, 16) (47712, 24)\n",
      "(43244609, 16) (47430, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove weekend dates for subjects who shouldn't be in the weekend data\n",
    "print(thedata.shape, thetiming.shape)\n",
    "for anid in rmweekends.UID:\n",
    "    thedata = thedata.query('~((UID == @anid)&(is_weekend == True))')\n",
    "    thetiming = thetiming.query('~((UID == @anid)&(OutofSchool == True))')\n",
    "print(thedata.shape, thetiming.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     43244609\n",
       "unique           2\n",
       "top          False\n",
       "freq      31506511\n",
       "Name: is_weekend, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thedata['is_weekend'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio is still good\n",
    "31.5/43.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK calculate on only the good data\n",
    "allData=thedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allddate= pd.Series( allData.index.date )\n",
    "holidays = calendar().holidays(start=timingData.Date.min(), end=timingData.Date.max())\n",
    "allData['is_holiday'] = allddate.apply( lambda x: holidays.isin([x]).any())\n",
    "allData['OutofSchool'] = allData['is_weekend'] | allData['is_holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fall 220 2015', 'Fall 220 2016', 'Spring 418 2016',\n",
       "       'Spring 418 2017', 'Spring 418 2018', 'Summer 220 2016',\n",
       "       'Summer 220 2017', 'Winter 220 2018'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData['Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpart = allData['OutofSchool'].apply(lambda x: 'Non-school day' if x else 'School day')\n",
    "allData['GroupDayType'] = allData['Group'].str.cat( dpart, sep=' ')\n",
    "allData['UIDDayType'] = allData['UID'].str.cat( dpart, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.920833333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hours_float( dttm ):\n",
    "    # takes timestamp, returns floating point hours description of the time  \n",
    "    if pd.isna(dttm):\n",
    "        return np.NaN\n",
    "    \n",
    "    td = pd.Timedelta( dttm.time().isoformat() )\n",
    "    return td.total_seconds() / 3600. \n",
    "\n",
    "hours_float( thetiming['First Light'].iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetiming['firstlight']=thetiming['First Light'].apply(lambda x: hours_float(x))\n",
    "thetiming['lastlight']=thetiming['Last Light'].apply(lambda x: hours_float(x))\n",
    "thetiming['lastlight']=thetiming['lastlight'].apply( lambda x: x if x>4.0 else x+24.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetiming.Date.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunset calc\n",
      "Sunrise calc\n"
     ]
    }
   ],
   "source": [
    "from astral import *\n",
    "a = Astral()\n",
    "\n",
    "dawns=[]\n",
    "dusks=[]\n",
    "dlookup = []\n",
    "dates = thetiming.Date.unique()\n",
    "\n",
    "for day in dates:\n",
    "    dlookup.append( a['Seattle'].sun(date=day) )\n",
    "    \n",
    "lookupday = pd.Series(dlookup,index=dates)\n",
    " \n",
    "print('Sunset calc')\n",
    "thetiming['Sunset'] = thetiming.Date.apply( lambda x: hours_float( lookupday[x]['sunset'] ) )\n",
    "print('Sunrise calc')\n",
    "thetiming['Sunrise'] = thetiming.Date.apply( lambda x: hours_float( lookupday[x]['sunrise'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetiming['hours from sunrise to first light abv threshold'] = thetiming['firstlight'] - thetiming['Sunrise']\n",
    "thetiming['hours from sunset to last light abv threshold'] = thetiming['lastlight'] - thetiming['Sunset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetiming.GroupDayType = thetiming.GroupDayType.apply(lambda x: x.replace('Weekday',' School day').replace('Weekend/Holiday',' Non-school day'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetiming.GroupDayType = thetiming.GroupDayType.apply(lambda x: x.replace(' School day','\\nSchool day').replace(' Non-school day','\\nNon-school day'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there was some accidental duplication the first time I was working out this analysis, won't be necessary in the future as I fixed the problem\n",
    "thetiming = thetiming.loc[:,~thetiming.columns.duplicated() ]\n",
    "thetiming.Date = thetiming.Date.astype('datetime64')\n",
    "thetiming['Watch period'] = pd.to_timedelta(thetiming['Watch period'])\n",
    "thetiming.to_parquet(outfile+'TimingAnalysis.parquet', engine='fastparquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = thetiming.query('Threshold == 50').groupby(['UID','OutofSchool'])['firstlight'].describe()\n",
    "result1.unstack().to_excel('../processed data/Time to 1st 50lux per person.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = thetiming.query('Threshold == 50').groupby(['UID','OutofSchool'])['Minutes above threshold'].describe()\n",
    "result2.unstack().to_excel('../processed data/Minutes above 50lux per person.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = thetiming.query('Threshold == 50').groupby(['UID','OutofSchool'])['Minutes above threshold AM'].describe()\n",
    "result3.unstack().to_excel('../processed data/Minutes above 50lux per person in the AM.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = thetiming.query('Threshold == 5').groupby(['UID','OutofSchool'])['Lux minutes'].describe()\n",
    "result4.unstack().to_excel('../processed data/Total lux minutes per person.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = thetiming.query('Threshold == 5').groupby(['UID','OutofSchool'])['Lux minutes AM'].describe()\n",
    "result5.unstack().to_excel('../processed data/Total lux minutes per person in the AM.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "( thetiming.query('Threshold == 50')[['UID','Date','OutofSchool','firstlight']]\n",
    "     .set_index(['UID','Date']).sort_index()\n",
    "     .to_excel('../processed data/Per person-day time to 1st 50lux.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "( thetiming.query('Threshold == 50')[['UID','Date','OutofSchool','Minutes above threshold']]\n",
    "     .set_index(['UID','Date']).sort_index()\n",
    "     .to_excel('../processed data/Per person-day minutes above 50lux.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "( thetiming.query('Threshold == 50')[['UID','Date','OutofSchool','Minutes above threshold AM']]\n",
    "     .set_index(['UID','Date']).sort_index()\n",
    "     .to_excel('../processed data/Per person-day time minutes above 50lux in the AM.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "( thetiming.query('Threshold == 5')[['UID','Date','OutofSchool','Lux minutes']]\n",
    "     .set_index(['UID','Date']).sort_index()\n",
    "     .to_excel('../processed data/Per person-day total lux min.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "( thetiming.query('Threshold == 5')[['UID','Date','OutofSchool','Lux minutes AM']]\n",
    "     .set_index(['UID','Date']).sort_index()\n",
    "     .to_excel('../processed data/Per person-day total lux min in the AM.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
